{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_hub.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungsunChoi914/Class2022Spring/blob/main/tensorflow_hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Tensorflow Hub](https://www.tensorflow.org/hub)"
      ],
      "metadata": {
        "id": "8dnF4rJPatAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fine-tuning"
      ],
      "metadata": {
        "id": "rDhfzyJ9854D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### image classification (e.g. [inception_v3](https://tfhub.dev/google/imagenet/inception_v3/classification/5))"
      ],
      "metadata": {
        "id": "soPd171Hbbma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "VIJXaAwQ9lXX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/classification/5\")"
      ],
      "metadata": {
        "id": "vmzDkBCZZMF-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)"
      ],
      "metadata": {
        "id": "f3ztc_fNX79F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "image = np.array(image)"
      ],
      "metadata": {
        "id": "znN6uHFw0nQ_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[:,:,0]"
      ],
      "metadata": {
        "id": "gr4OGGAI15yM",
        "outputId": "cbe36e27-52c3-4599-ae78-164b7520c875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.54901963, 0.09803922, 0.21960786],\n",
              "        [0.5411765 , 0.08627451, 0.22352943],\n",
              "        [0.5294118 , 0.08627451, 0.16470589],\n",
              "        ...,\n",
              "        [0.9294118 , 0.3921569 , 0.74509805],\n",
              "        [0.90196085, 0.32941177, 0.86666673],\n",
              "        [0.9333334 , 0.3921569 , 0.6862745 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape into shape [batch_size, height, width, num_channels]\n",
        "image = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n"
      ],
      "metadata": {
        "id": "Bqm9LV1rC4eK",
        "outputId": "8d1be605-602d-4bc9-a5d7-b8e6bf2170d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4de7e42bc132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reshape into shape [batch_size, height, width, num_channels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 921600 values, but the requested shape has 307200 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "image = tf.image.convert_image_dtype(image, tf.float32)"
      ],
      "metadata": {
        "id": "V3qMPw3F2FCJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[0,:,:,0]"
      ],
      "metadata": {
        "id": "RHZxtD2Y2YVx",
        "outputId": "23ffb1ee-ab27-476d-df6f-8451a2ae32e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(480, 640), dtype=float32, numpy=\n",
              "array([[0.54901963, 0.5647059 , 0.57254905, ..., 0.36862746, 0.41960788,\n",
              "        0.40000004],\n",
              "       [0.5411765 , 0.5568628 , 0.54509807, ..., 0.4039216 , 0.45098042,\n",
              "        0.37647063],\n",
              "       [0.5294118 , 0.5882353 , 0.5568628 , ..., 0.4039216 , 0.42352945,\n",
              "        0.3647059 ],\n",
              "       ...,\n",
              "       [0.9294118 , 0.882353  , 0.92549026, ..., 0.67058825, 0.70980394,\n",
              "        0.5764706 ],\n",
              "       [0.90196085, 0.8862746 , 0.9333334 , ..., 0.44705886, 0.4039216 ,\n",
              "        0.34901962],\n",
              "       [0.9333334 , 0.96470594, 0.9333334 , ..., 0.2901961 , 0.2901961 ,\n",
              "        0.28627452]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지를 array 형태로 바꾸고, reshape 해야 사용 가능. \n",
        "\n",
        "이미지가 3차원의 array인데, 모델 특성상 4차원의 array로 바꿔야 함. \n",
        "\n",
        "0~1 사이 숫자로 바꿔줌"
      ],
      "metadata": {
        "id": "7QcYXTCtzwkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(image)\n",
        "np.argmax(logits)"
      ],
      "metadata": {
        "id": "CRUy_pik9m3o",
        "outputId": "50f65493-6093-4161-9c3b-7674d465bd2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "282"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.argmax 가장 높은 값 찾는 함수\n",
        "\n",
        "282번째가 가장 큼. "
      ],
      "metadata": {
        "id": "RuAoUBd72sL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt"
      ],
      "metadata": {
        "id": "p7zLDQqWaGii"
      }
    }
  ]
}